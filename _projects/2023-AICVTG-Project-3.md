---
title: "AICVTG: Automatic Image Captioning"
collection: projects
permalink: /projects/2023-AICVTG-Project-3
excerpt: "An image captioning project using a Vision Transformer encoder and GPT-2 decoder on the MSCOCO dataset."
date: 2023-01-20
venue: "North South University"
---

This project investigates **automatic image captioning** by combining computer vision and natural language generation.

Model approach:

- **Vision Transformer (ViT)** as the image encoder
- **GPT-2** as the language decoder
- **MSCOCO** as the primary training/evaluation dataset

The work focuses on end-to-end caption generation quality, evaluation across standard captioning metrics, and practical analysis of multimodal model behavior.

![Project Image](/files/projects/project3-AICVTG-Block.png)

Figure 1. Block diagram of the proposed approach

![Project Image](/files/projects/project3-AICVTG-ViT.png)

Figure 2. Vision Transformer architecture

![Project Image](/files/projects/project3-AICVTG-ViT-Arc.png)

Figure 3. End-to-end ViT-GPT framework

[Project Demo](https://huggingface.co/Zayn/AICVTG_What_if_a_machine_could_create_captions_automatically)

Supervisor: Prof. Shafin Rahman  
Authors: Nishan, Shafiul Bashar, Md. Imran Hossain

